数字音频
采样－量化－编码


采样-根据奈奎斯特定理　按比声音最高频率的２倍以上的频率对声音进行采样一般为　44.1kHz(人耳20Hz~20kHz)
量化-用１６比特表示一个采样，最终音频信号在幅度上分为［－３２７６８，３２７６７］共６５５３６层
编码-编码源数据格式未脉冲编码调制（ＰＣＭ），描述一段pcm需要的概念：量化格式（或深度，如１６比特／２字节），采样率（如４４１００），声道数（如２）．这些信息描述了声音的音质
对于声音格式，可以用　数据比特率　描述声音的大小，即一秒内的比特数目如上例：bitrates:44100*16*2=1378.125kbps
那么一分钟内的大小为　１３７８．１２５　＊　６０　／８　／１０２４　＝　１０．０９ＭＢ


音频编码-为了传输的要求对大小进行压缩，ＰＣＭ，ＷＡＶ，ＡＡＣ，ＭＰ３，Ｏgg等．
wav-（音质非常好）不进行压缩操作，在pcm数据前加上４４字节描述采样率声道数数据格式等信息．
mp3-较高压缩比，音质在128Kbit/s以上时音质比较好，使用lame编码
AAC-在小于128Kbit/s时表现好，一般用与视频中的音频编码，新一代有损压缩技术，通过附件的编码技术（比如ps,sbr等）衍生出了LC-AAC（使用场景大于等于80Kbit/s）,HE-AAC(小于等于80Kbit.s),HE-AACv2(小于等于48Kbit/s)三主编码格式．

Ogg-可以用比mp3更小的码率实现比mp3更好的音质，高中低码率下都有良好的表现，兼容性差，潜力较大．适用于语音聊天等．


三原色：Ｒ（红色）Ｇ（绿色）Ｂ（蓝色）
屏幕像素　x * y  横向y个像素，纵向x个像素
每个像素点由三个子像素点组成．
单个像素点的ＲＧＢ表示方法：
浮点：０．０～１．０　（OpenGL ES）
整数：０～２５５或者００～ＦＦ，８个比特表示一个子像素，３２个比特表示一个像素（ＲＧＢＡ＿８８８８）
ＲＧＢ＿５６５　１６个比特（５Ｒ，６Ｇ，５Ｂ）
一张1280*720的RGBA_8888的大小为1280*720*4=3.516MB,也使位图（bitmap）在内存中所占用的大小
传输的压缩方法：
比如ＪＰＥＧ：一种有损压缩，不能用与视频压缩，视频要考虑帧内编码和帧间编码


ＹＵＶ：视频帧的表现格式，与ＲＧＢ不同，占用极少的频宽（ＲＧＢ三个独立视频信号同时传输），Ｙ（明亮度也称灰阶值　Luminance或Luma）Ｕ和Ｖ表示色度（Chrominance或Chroma）用来描述色彩及饱和度指定像素的颜色．色度定义类色调Cr和饱和度Cb
YUV每个８字节（０～２５５）表示，Ｙ（１６～２３５）ＵＶ都是１６～２４０
ＩＳＯ制定的ＭＰＥＧ一种动态视频的压缩算法，分为：Mpeg1(VCD),Mpeg2(DVD),Mpeg4 AVC(现在最多的流媒体压缩方式)
ＩＴＵ－Ｔ制定的Ｈ．２６１，Ｈ．２６２，Ｈ．２６３，Ｈ．２６４（包含前面所有的优点），现在使用最多的标准．

ＩＰＢ帧
Ｉ（帧内编码帧）：去除空间冗余信息，每个ＧＯＰ（ＭＰＥＧ使用的一种视频压缩技术）的第一个帧压缩后作为随机访问的参考点．可当作静态图像．
Ｐ(前向预测编码帧):去除时间冗余，也称预测帧
Ｂ(双向预测内插编码帧):去除时间冗余，也称双向预测帧

ＩＤＲ帧是Ｈ２６４中的一个帧，Ｈ２６４采用多帧预测，Ｐ帧可能会参考Ｉ帧之前的帧，所以随机访问时不能用Ｉ帧作为参考条件，因为即使找到Ｉ帧，之后的信息也可能解析不出来，ＩＤＲ帧是一种特殊的Ｉ帧，这一帧之后的所有参考帧只会参考这个ＩＤＲ帧而不会再参考之前的帧．在解码器中，一旦收到一个ＩＤＲ帧，就会立即清理参考帧缓冲区，并将该ＩＤＲ帧作为被参考的帧．

两种解码时间戳
ＤＴＳ用于视频解码
ＰＴＳ解码阶段进行视频的同步输出
在无Ｂ帧时输出顺序一样，一旦有Ｂ帧，势必不同　，因为Ｂ帧打乱了解码顺序．
硬件编码器可以重新设置ＤＴＳ和ＰＴＳ值，为了将硬件编码器和FFmpeg结合．
FFmpeg中使用AVPacket　结构体描述解码前后的压缩数据
	使用AVFrame　结构体描述解码前后的原始数据
ＧＯＰ两个Ｉ帧之间的一组图片，必须要设置gop_size的值，表示俩Ｉ帧之间的帧数目，ＧＯＰ越大，质量越好
提高视频质量还有一个技巧，多使用Ｂ帧　．压缩率Ｉ　７，Ｐ　２０，Ｂ　５０，所以Ｂ帧可以节省大量


